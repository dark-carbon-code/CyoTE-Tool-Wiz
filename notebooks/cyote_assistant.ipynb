{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca47439",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langchain langchain-community faiss-cpu ollama openai tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install notebook ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f05cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and paths\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "CHUNK_FILE = Path(r\"C:\\Projects\\cyote_tool_wiz\\data\\chunks\\RAG_Ready_Test_chunks.jsonl\")\n",
    "assert CHUNK_FILE.exists(), f\"Chunk file not found: {CHUNK_FILE}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200c37b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 179 chunks for retrieval.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load chunks\n",
    "with open(CHUNK_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_chunks = [json.loads(line) for line in f]\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=chunk[\"content\"],\n",
    "        metadata={\n",
    "            \"tool_name\": chunk[\"tool_name\"],\n",
    "            \"section\": chunk[\"section\"],\n",
    "            \"tactics_supported\": chunk.get(\"tactics_supported\", []),\n",
    "            \"techniques_supported\": chunk.get(\"techniques_supported\", [])\n",
    "        }\n",
    "    )\n",
    "    for chunk in raw_chunks\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(documents)} chunks for retrieval.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97c0538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e379960efb45b2b766bcdefe320ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding Chunks:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Building FAISS index...\n",
      "‚úÖ Vector index built and retriever ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Build FAISS vector store using embedding-compatible Ollama model with progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# ‚úÖ Initialize Ollama embedding model\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# üß† Extract raw text and metadata from documents\n",
    "texts = [doc.page_content for doc in documents]\n",
    "metadatas = [doc.metadata for doc in documents]\n",
    "\n",
    "# üöÄ Generate embeddings with progress bar\n",
    "print(\"üîç Generating embeddings...\")\n",
    "vectors = []\n",
    "for text in tqdm(texts, desc=\"Embedding Chunks\"):\n",
    "    vectors.append(embedding.embed_query(text))\n",
    "\n",
    "# üèóÔ∏è Build FAISS index from embeddings\n",
    "print(\"üîß Building FAISS index...\")\n",
    "text_embedding_pairs = list(zip(texts, vectors))  # ‚úÖ format fix\n",
    "vectorstore = FAISS.from_embeddings(text_embedding_pairs, embedding=embedding, metadatas=metadatas)\n",
    "\n",
    "# üîç Create retriever interface\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"‚úÖ Vector index built and retriever ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c5cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from IPython.display import display, Markdown\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class NotebookStreamHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.tokens = []\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.tokens.append(token)\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(\"\".join(self.tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0dd2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Setup LLM-powered Q&A with streaming using ChatOllama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# üß† Use chat-capable model with streaming\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:12b\",  # ensure this is a chat-friendly model\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# üîç Setup RetrievalQA with retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6301ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down what's known about Havex, its associated MITRE ATT&CK techniques for ICS/OT, and the OT protocols it's known to interact with. I'll also address the limitations regarding my current information access.\n",
      "\n",
      "**What is Havex? (And What We *Do* Know - With Caveats)**\n",
      "\n",
      "Havex is a sophisticated, modular malware platform primarily targeting Industrial Control Systems (ICS) and Operational Technology (OT) environments.  Here's a summary of what has been publicly reported, bearing in mind that information has been fragmented and sometimes difficult to fully confirm due to the nature of these attacks:\n",
      "\n",
      "*   **Discovery & Attribution (Uncertainties):** Havex was initially identified in 2016. Its origins are murky. While initially attributed to Russia/APT28, this attribution is not universally accepted and is controversial within the security community. It's possible multiple actors are using or have used the framework.  The uncertainty in attribution makes it challenging to definitively analyze the full scope of the threat.\n",
      "*   **Modular Architecture:**  This is a key characteristic.  Havex isn't a single executable; it's a framework consisting of numerous modules.  These modules perform different tasks, like data collection, remote command execution, communication, and persistence. This modularity allows attackers to customize the malware for specific targets and purposes.\n",
      "*   **Primary Target: Critical Infrastructure:**  The focus is on critical infrastructure sectors, including energy, oil & gas, and potentially utilities.  This demonstrates a focus on disruption or data theft with potentially significant real-world consequences.\n",
      "*   **Staging & Persistence:**  Havex typically uses a stager (a small initial payload) to download the main modules from a remote server.  Persistence mechanisms are employed to ensure the malware remains active even after system reboots.\n",
      "*   **Data Exfiltration:** It's capable of collecting data from ICS devices and systems, including process values, configuration data, and other operational information.  This data is then exfiltrated to attacker-controlled servers.\n",
      "*   **PLC Programming Logic Modification (Reported, Controversial):** One of the most concerning and controversial aspects is the reported capability to modify PLC (Programmable Logic Controller) programming logic.  This is a potentially devastating capability because it could directly manipulate the control processes of industrial equipment.  However, the evidence supporting this specific capability has been debated. Some believe it may be a misinterpretation or a more advanced derivative.\n",
      "\n",
      "**What I *Don't* Know, and Limitations**\n",
      "\n",
      "*   **Complete Module List:** The exact list of available modules and their functionalities is not fully known.  The framework likely evolves over time, and new modules are added.\n",
      "*   **Current Activity:**  Assessing whether Havex is *currently* actively used in attacks is difficult.  Information about ongoing campaigns is often limited.\n",
      "*   **Advanced Techniques:**  The full extent of Havex's capabilities, particularly regarding PLC modification and advanced evasion techniques, is not completely understood. The information often emerges piecemeal from security vendor reports and research.\n",
      "*   **Specific Infrastructure Details:** I lack access to real-time threat intelligence feeds or specific details about compromised systems.\n",
      "\n",
      "**MITRE ATT&CK for ICS Techniques (Associated with Havex - Based on Available Reporting)**\n",
      "\n",
      "Given what's been reported, here's a mapping of Havex's capabilities to MITRE ATT&CK for ICS techniques. **Please note:** This is based on publicly available information and may not be exhaustive.\n",
      "\n",
      "*   **T1003 - OS Credential Dumping:** (Likely used to obtain credentials for accessing systems and ICS devices)\n",
      "*   **T1018 - Remote System Discovery:** (For identifying systems on the network)\n",
      "*   **T1021 - Remote System Tasking:** (For executing commands on remote systems)\n",
      "*   **T1047 - Windows Service:** (To establish persistence and run malicious code)\n",
      "*   **T1059.001 - Command and Scripting Interpreter:** (Using scripting languages like PowerShell for reconnaissance and execution)\n",
      "*   **T1071.001 - Application Layer Protocol: Web Protocols:** (For communication and data exfiltration)\n",
      "*   **T1071.002 - Application Layer Protocol: Structured Query Language (SQL):** (potentially for database interaction)\n",
      "*   **T1082 - System Information Discovery:** (Gathering information about systems and configurations)\n",
      "*   **T1105 - Ingress Tool Transfer:** (Downloading malware components and modules)\n",
      "*   **T1133 - External Remote Services:** (Communicating with command-and-control servers)\n",
      "*   **T1210 - Exploitation for Client Capabilities:** (Potential exploitation of vulnerabilities)\n",
      "*   **T1547.003 - Boot or Logon Autostart Execution:** (Persistence)\n",
      "*   **T1574 - Hijack Execution Flow:** (If PLC modification is confirmed - this would be relevant)\n",
      "*   **T1594.003 - System Information Discovery (ICS/OT):** (Gathering information about PLCs, HMIs, SCADA systems)\n",
      "*   **T1598.003 - System Information Discovery (ICS/OT):** (Gathering device details)\n",
      "\n",
      "**OT Protocols Used (Based on Reported Activity)**\n",
      "\n",
      "The specific protocols utilized can vary depending on the target environment and the modules deployed. However, based on available information, Havex has been associated with:\n",
      "\n",
      "*   **Modbus:** A very common protocol in industrial environments for communication between PLCs and HMIs.  Havex likely uses it for data collection and potentially command execution.\n",
      "*   **OPC (OLE for Process Control):** Another widely used protocol in SCADA systems.  It provides access to real-time data from industrial processes.\n",
      "*   **DNP3 (Distributed Network Protocol):** Used in critical infrastructure, particularly in the electric utility sector.\n",
      "*   **SSH (Secure Shell):** Used for remote access to devices.\n",
      "*   **HTTP/HTTPS:** For communication with command-and-control servers and data exfiltration.\n",
      "\n",
      "**Important Considerations**\n",
      "\n",
      "*   **Defensive Measures:**  Robust network segmentation, intrusion detection systems (IDS), endpoint detection and response (EDR) solutions, and strict access control policies are essential for mitigating the risk of Havex and similar threats.  Regular patching of systems and devices is also crucial.\n",
      "*   **Threat Intelligence:** Staying informed about the latest threat intelligence related to Havex and other ICS/OT malware is vital for proactive defense.\n",
      "*   **PLC Security:** Given the reported (but debated) PLC modification capability, organizations should implement measures to protect PLC programming logic, such as digital signatures, version control, and access controls.\n",
      "\n",
      "\n",
      "\n",
      "**Disclaimer:** I am an AI chatbot and cannot provide definitive security assessments or guarantees. The information provided here is based on publicly available reports and is subject to change.\n",
      "üìö Sources:\n",
      "‚Üí RAG Ready Test (export_formats]_mitre_attack_flow_(json))\n",
      "‚Üí RAG Ready Test (output_types]_mitre_att&ck_mapping_file)\n",
      "‚Üí RAG Ready Test (techniques_supported)\n",
      "‚Üí RAG Ready Test (input_types]_stix_2.1_bundle)\n",
      "‚Üí RAG Ready Test (import_formats]_stix_2.1_bundle)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Ask a CyOTE-aware threat hunt question (FrostyGoop context)\n",
    "query = (\n",
    "    \"Tell me about havex malware. If you don't have access to information about it tell me. What are the MITRE ATT&CK for ICS Techniques associated with it? Which OT protocols does it use?\"\n",
    ")\n",
    "\n",
    "result = qa_chain.invoke({\"query\": query})  # use `.invoke()` for streaming-enabled chains\n",
    "\n",
    "# ‚úÖ After answer is streamed, print sources\n",
    "print(\"\\nüìö Sources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"‚Üí {doc.metadata['tool_name']} ({doc.metadata['section']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and paths\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# üß† New: Custom loader\n",
    "from utils.db_loader import load_jsonl_chunks, load_db_entries\n",
    "\n",
    "# Paths to input sources\n",
    "CHUNK_FILE = Path(\"data/chunks/RAG_Ready_Test_chunks.jsonl\")\n",
    "DB_PATH = Path(\"data/tool_knowledge.db\")\n",
    "\n",
    "assert CHUNK_FILE.exists(), f\"‚ùå Chunk file not found: {CHUNK_FILE}\"\n",
    "assert DB_PATH.exists(), f\"‚ùå Database not found: {DB_PATH}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load documents from .jsonl and tool_knowledge.db\n",
    "jsonl_docs = load_jsonl_chunks(CHUNK_FILE)\n",
    "db_docs = load_db_entries(DB_PATH)\n",
    "\n",
    "# üß© Combine them for embedding\n",
    "documents = jsonl_docs + db_docs\n",
    "print(f\"üìö Total documents: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447213db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Build FAISS vector store using embedding-compatible Ollama model with progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "texts = [doc.page_content for doc in documents]\n",
    "metadatas = [doc.metadata for doc in documents]\n",
    "\n",
    "print(\"üîç Generating embeddings...\")\n",
    "vectors = []\n",
    "for text in tqdm(texts, desc=\"Embedding Chunks\"):\n",
    "    vectors.append(embedding.embed_query(text))\n",
    "\n",
    "print(\"üîß Building FAISS index...\")\n",
    "vectorstore = FAISS.from_embeddings(vectors, texts, metadatas=metadatas)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(\"‚úÖ Vector index built and retriever ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Setup LLM-powered Q&A (streaming optional)\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Use an Ollama-supported model with chat capability\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",  # Change to \"mistral\" or another if needed\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"üß† QA chain ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Ask a contextual threat hunt question\n",
    "query = \"Which CyOTE tools can help in a threat hunt involving the FrostyGoop malware and the associated MITRE ATT&CK for ICS tactics and techniques?\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": query})  # Use `.invoke()` instead of `qa_chain(query)`\n",
    "\n",
    "print(\"üîé Answer:\\n\")\n",
    "print(result['result'])\n",
    "\n",
    "print(\"\\nüìö Sources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"‚Üí {doc.metadata.get('tool_name', 'Unknown Tool')} ({doc.metadata.get('section', 'unknown section')})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46375eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What observable types are most useful for detecting this malware?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"üîé Answer:\\n\")\n",
    "print(result['result'])\n",
    "\n",
    "print(\"\\nüìö Sources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"‚Üí {doc.metadata.get('tool_name', 'Unknown Tool')} ({doc.metadata.get('section', 'unknown section')})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Browse document metadata (for debugging or fine-tuning)\n",
    "from collections import Counter\n",
    "\n",
    "tool_names = [doc.metadata.get(\"tool_name\", \"unknown\") for doc in documents]\n",
    "print(f\"üõ†Ô∏è Tools Represented: {Counter(tool_names)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
